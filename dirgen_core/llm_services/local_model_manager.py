#!/usr/bin/env python3
"""
Gestor Din√°mico de Modelos Locales para DirGen Platform

Este m√≥dulo maneja autom√°ticamente el inicio, monitoreo y parada de modelos locales
ejecut√°ndose en Docker, optimizando el uso de recursos del sistema.
"""

import json
import logging
import os
import subprocess
import threading
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Set

logger = logging.getLogger(__name__)

class LocalModelManager:
    """Gestor din√°mico para modelos LLM locales ejecut√°ndose en Docker"""
    
    def __init__(self, 
                 idle_timeout: int = 300,  # 5 minutos sin uso
                 startup_timeout: int = 120,  # 2 minutos para iniciar (aumentado)
                 max_concurrent_models: int = 2):  # M√°ximo 2 modelos simult√°neos
        
        self.idle_timeout = idle_timeout
        self.startup_timeout = startup_timeout
        self.max_concurrent_models = max_concurrent_models
        
        # Estado interno
        self._active_models: Dict[str, Dict] = {}  # modelo_id -> metadata
        self._model_locks: Dict[str, threading.Lock] = {}
        self._cleanup_thread: Optional[threading.Thread] = None
        self._cleanup_running = False
        
        # Configuraci√≥n
        self._docker_command = "docker"  # Puede ser 'podman' u otro
        
        logger.info(f"ü§ñ LocalModelManager inicializado - Timeout: {idle_timeout}s, Max concurrent: {max_concurrent_models}")
    
    def start_cleanup_thread(self):
        """Inicia el hilo de limpieza autom√°tica"""
        if self._cleanup_thread is None or not self._cleanup_thread.is_alive():
            self._cleanup_running = True
            self._cleanup_thread = threading.Thread(target=self._cleanup_worker, daemon=True)
            self._cleanup_thread.start()
            logger.info("üßπ Hilo de limpieza autom√°tica iniciado")
    
    def stop_cleanup_thread(self):
        """Detiene el hilo de limpieza autom√°tica"""
        self._cleanup_running = False
        if self._cleanup_thread and self._cleanup_thread.is_alive():
            self._cleanup_thread.join(timeout=5)
            logger.info("üõë Hilo de limpieza autom√°tica detenido")
    
    def _cleanup_worker(self):
        """Worker que ejecuta limpieza peri√≥dica de modelos inactivos"""
        while self._cleanup_running:
            try:
                self._cleanup_idle_models()
                time.sleep(30)  # Revisar cada 30 segundos
            except Exception as e:
                logger.error(f"Error en cleanup worker: {e}")
                time.sleep(10)
    
    def _cleanup_idle_models(self):
        """Detiene modelos que han estado inactivos por mucho tiempo"""
        current_time = datetime.now()
        models_to_stop = []
        
        for model_id, metadata in self._active_models.items():
            last_used = metadata.get('last_used', current_time)
            idle_time = (current_time - last_used).total_seconds()
            
            if idle_time > self.idle_timeout:
                models_to_stop.append(model_id)
        
        for model_id in models_to_stop:
            logger.info(f"üßπ Deteniendo modelo inactivo: {model_id}")
            self._stop_model(model_id, reason="timeout por inactividad")
    
    def is_model_running(self, model_id: str) -> bool:
        """Verifica si un modelo est√° ejecut√°ndose actualmente"""
        try:
            result = subprocess.run([
                self._docker_command, "model", "ps"
            ], capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0:
                output_lines = result.stdout.strip().split('\n')
                # La primera l√≠nea es el header, verificamos las siguientes
                for line in output_lines[1:]:  # Saltar header
                    if line.strip():
                        # El formato es: MODEL NAME  BACKEND  MODE  LAST USED
                        columns = line.split()
                        if len(columns) >= 1 and columns[0] == model_id:
                            logger.info(f"‚úÖ Modelo {model_id} detectado como activo")
                            return True
            
            return False
            
        except subprocess.TimeoutExpired:
            logger.warning(f"Timeout verificando estado de {model_id}")
            return False
        except Exception as e:
            logger.error(f"Error verificando modelo {model_id}: {e}")
            return False
    
    def get_running_models(self) -> List[str]:
        """Obtiene lista de todos los modelos actualmente ejecut√°ndose"""
        try:
            result = subprocess.run([
                self._docker_command, "model", "ps"
            ], capture_output=True, text=True, timeout=10)
            
            running_models = []
            if result.returncode == 0:
                output_lines = result.stdout.strip().split('\n')
                # La primera l√≠nea es el header, procesamos las siguientes
                for line in output_lines[1:]:  # Saltar header
                    if line.strip():
                        # El formato es: MODEL NAME  BACKEND  MODE  LAST USED
                        columns = line.split()
                        if len(columns) >= 1:
                            running_models.append(columns[0])  # Primer columna es el nombre
            
            return running_models
            
        except Exception as e:
            logger.error(f"Error obteniendo modelos ejecut√°ndose: {e}")
            return []
    
    def _start_model(self, model_id: str) -> bool:
        """Inicia un modelo local usando Docker"""
        try:
            logger.info(f"üöÄ Iniciando modelo local: {model_id}")
            
            # Verificar si ya est√° ejecut√°ndose
            if self.is_model_running(model_id):
                logger.info(f"‚úÖ Modelo {model_id} ya est√° ejecut√°ndose")
                self._update_model_metadata(model_id, 'already_running')
                return True
            
            # Verificar l√≠mite de modelos concurrentes
            running_count = len(self.get_running_models())
            if running_count >= self.max_concurrent_models:
                logger.warning(f"‚ö†Ô∏è L√≠mite de modelos concurrentes alcanzado ({running_count}/{self.max_concurrent_models})")
                # Intentar detener el modelo menos usado
                self._stop_least_used_model()
            
            # Docker Model Run es interactivo, por lo que lo ejecutamos en segundo plano
            # y verificamos que se inicie correctamente
            start_time = time.time()
            
            try:
                # Docker model run necesita un prompt para iniciarse, luego podemos usarlo como servicio
                # Usamos un prompt inicial simple para "despertar" el modelo
                process = subprocess.Popen([
                    self._docker_command, "model", "run", model_id, "Hello"
                ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, 
                   stdin=subprocess.PIPE, text=True)
                
                # Dar tiempo para que el modelo procese el prompt inicial
                time.sleep(10)  # M√°s tiempo para que el modelo se cargue y responda
                
                # Verificar si el proceso a√∫n se est√° ejecutando (procesando o listo)
                poll_result = process.poll()
                if poll_result is not None:
                    # El proceso termin√≥ - esto podr√≠a ser normal si complet√≥ el prompt
                    try:
                        stdout, stderr = process.communicate(timeout=2)
                        if poll_result == 0:
                            # Salida exitosa - el modelo probablemente respondi√≥ al prompt
                            logger.info(f"‚úÖ Modelo {model_id} proces√≥ prompt inicial exitosamente")
                            if stdout:
                                logger.info(f"   Respuesta: {stdout.strip()[:100]}...")
                        else:
                            # Error en el proceso
                            error_msg = stderr.strip() if stderr else "Error desconocido"
                            logger.error(f"‚ùå Error iniciando {model_id}: {error_msg}")
                            logger.error(f"   C√≥digo de salida: {poll_result}")
                            return False
                    except Exception as comm_e:
                        logger.error(f"‚ùå Error comunicando con proceso {model_id}: {comm_e}")
                        return False
                
                # Verificar que el modelo est√© realmente ejecut√°ndose
                max_checks = 12  # 60 segundos total (5s * 12)
                for attempt in range(max_checks):
                    if self.is_model_running(model_id):
                        elapsed = time.time() - start_time
                        logger.info(f"‚úÖ Modelo {model_id} iniciado exitosamente en {elapsed:.1f}s")
                        self._update_model_metadata(model_id, 'started')
                        # Guardar el proceso para poder detenerlo despu√©s
                        if not hasattr(self, '_model_processes'):
                            self._model_processes = {}
                        self._model_processes[model_id] = process
                        return True
                    
                    time.sleep(5)  # Esperar 5 segundos entre verificaciones
                    logger.info(f"‚è≥ Esperando que {model_id} est√© disponible (intento {attempt + 1}/{max_checks})...")
                
                # Si llegamos aqu√≠, el modelo no se inici√≥ en el tiempo esperado
                logger.error(f"‚ùå Timeout: {model_id} no se inici√≥ en {max_checks * 5} segundos")
                process.terminate()  # Terminar el proceso colgado
                return False
                
            except Exception as e:
                logger.error(f"‚ùå Error cr√≠tico iniciando {model_id}: {e}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error(f"‚ùå Timeout iniciando {model_id} (>{self.startup_timeout}s)")
            return False
        except Exception as e:
            logger.error(f"‚ùå Error cr√≠tico iniciando {model_id}: {e}")
            return False
    
    def _stop_model(self, model_id: str, reason: str = "solicitud manual") -> bool:
        """Detiene un modelo local usando Docker y terminando el proceso"""
        try:
            logger.info(f"üõë Deteniendo modelo: {model_id} (raz√≥n: {reason})")
            
            success = False
            
            # Primero, intentar terminar el proceso directamente si existe
            if hasattr(self, '_model_processes') and model_id in self._model_processes:
                try:
                    process = self._model_processes[model_id]
                    if process.poll() is None:  # Proceso a√∫n ejecut√°ndose
                        process.terminate()
                        process.wait(timeout=5)  # Esperar hasta 5 segundos
                        logger.info(f"‚úÖ Proceso de {model_id} terminado directamente")
                        success = True
                    del self._model_processes[model_id]
                except Exception as proc_e:
                    logger.warning(f"‚ö†Ô∏è No se pudo terminar proceso directamente: {proc_e}")
            
            # Intentar usar docker model unload como alternativa
            try:
                result = subprocess.run([
                    self._docker_command, "model", "unload", model_id
                ], capture_output=True, text=True, timeout=15)
                
                if result.returncode == 0:
                    logger.info(f"‚úÖ Modelo {model_id} descargado exitosamente")
                    success = True
                else:
                    error_msg = result.stderr.strip() or result.stdout.strip()
                    logger.warning(f"‚ö†Ô∏è Problema descargando {model_id}: {error_msg}")
            except Exception as unload_e:
                logger.warning(f"‚ö†Ô∏è Error con docker model unload: {unload_e}")
            
            if success:
                self._remove_model_metadata(model_id)
            
            return success
                
        except Exception as e:
            logger.error(f"‚ùå Error deteniendo {model_id}: {e}")
            return False
    
    def _stop_least_used_model(self):
        """Detiene el modelo que ha sido usado menos recientemente"""
        if not self._active_models:
            return
        
        # Encontrar modelo menos usado
        least_used_model = min(
            self._active_models.items(), 
            key=lambda x: x[1].get('last_used', datetime.min)
        )[0]
        
        logger.info(f"üîÑ Deteniendo modelo menos usado para liberar espacio: {least_used_model}")
        self._stop_model(least_used_model, reason="liberar espacio para nuevo modelo")
    
    def _update_model_metadata(self, model_id: str, action: str):
        """Actualiza metadatos de uso de un modelo"""
        current_time = datetime.now()
        
        if model_id not in self._active_models:
            self._active_models[model_id] = {
                'started_at': current_time,
                'total_requests': 0
            }
        
        self._active_models[model_id].update({
            'last_used': current_time,
            'last_action': action,
            'total_requests': self._active_models[model_id].get('total_requests', 0) + 1
        })
    
    def _remove_model_metadata(self, model_id: str):
        """Elimina metadatos de un modelo detenido"""
        if model_id in self._active_models:
            del self._active_models[model_id]
        if model_id in self._model_locks:
            del self._model_locks[model_id]
        # Limpiar procesos si existen
        if hasattr(self, '_model_processes') and model_id in self._model_processes:
            del self._model_processes[model_id]
    
    def ensure_model_running(self, model_id: str) -> bool:
        """
        Asegura que un modelo est√© ejecut√°ndose, inici√°ndolo si es necesario
        
        Returns:
            bool: True si el modelo est√° disponible, False si fall√≥
        """
        if not model_id or not model_id.startswith('ai/'):
            logger.warning(f"‚ö†Ô∏è ID de modelo inv√°lido: {model_id}")
            return False
        
        # Obtener lock para este modelo espec√≠fico
        if model_id not in self._model_locks:
            self._model_locks[model_id] = threading.Lock()
        
        with self._model_locks[model_id]:
            # Verificar si ya est√° ejecut√°ndose
            if self.is_model_running(model_id):
                self._update_model_metadata(model_id, 'used')
                return True
            
            # Iniciar el modelo si no est√° ejecut√°ndose
            logger.info(f"üîÑ Modelo {model_id} no est√° activo, iniciando bajo demanda...")
            success = self._start_model(model_id)
            
            if success:
                # Iniciar cleanup thread si no est√° activo
                self.start_cleanup_thread()
            
            return success
    
    def get_model_stats(self) -> Dict:
        """Obtiene estad√≠sticas de uso de modelos"""
        running_models = self.get_running_models()
        
        return {
            'running_models': running_models,
            'active_count': len(running_models),
            'max_concurrent': self.max_concurrent_models,
            'managed_models': list(self._active_models.keys()),
            'cleanup_active': self._cleanup_running,
            'model_details': self._active_models.copy()
        }
    
    def force_stop_all(self):
        """Detiene todos los modelos gestionados (para shutdown)"""
        logger.info("üõë Deteniendo todos los modelos gestionados...")
        
        self.stop_cleanup_thread()
        
        models_to_stop = list(self._active_models.keys())
        for model_id in models_to_stop:
            self._stop_model(model_id, reason="shutdown del sistema")
        
        logger.info("üîö Todos los modelos han sido detenidos")


# Instancia global del gestor
_model_manager = None

def get_model_manager() -> LocalModelManager:
    """Obtiene la instancia global del gestor de modelos"""
    global _model_manager
    if _model_manager is None:
        _model_manager = LocalModelManager()
    return _model_manager

def ensure_model_available(model_id: str) -> bool:
    """Funci√≥n de conveniencia para asegurar que un modelo est√© disponible"""
    if not model_id or not model_id.startswith('ai/'):
        return True  # No es un modelo local, asumir disponible
    
    manager = get_model_manager()
    return manager.ensure_model_running(model_id)